
# ğŸ¡ House Price Prediction System â€” ZenML + MLflow MLOps Pipeline  

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![MLflow](https://img.shields.io/badge/MLflow-Experiment_Tracking-orange)](https://mlflow.org/)
[![ZenML](https://img.shields.io/badge/ZenML-MLOps_Pipeline-green)](https://zenml.io/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-ML_Modeling-yellow)](https://scikit-learn.org/)
[![Status](https://img.shields.io/badge/Status-Active-brightgreen)]()

---

## ğŸš€ Overview  

This project demonstrates an **end-to-end MLOps workflow** for predicting house prices using **ZenML** for pipeline orchestration and **MLflow** for experiment tracking.  
It takes a standard machine learning problem â€” *House Price Prediction* â€” and elevates it into a **production-ready ML system**.  

---

## ğŸ§© Tech Stack  

| Tool / Framework | Purpose |
|------------------|----------|
| ğŸ **Python** | Core programming language |
| ğŸ“Š **Pandas, NumPy** | Data preprocessing and transformation |
| ğŸ¤– **Scikit-learn** | Model training and evaluation |
| ğŸ§  **MLflow** | Experiment tracking and model registry |
| âš™ï¸ **ZenML** | Pipeline orchestration and reproducibility |
| ğŸ’» **Streamlit (optional)** | UI for serving predictions |

---

## ğŸ—ï¸ Project Architecture  

```bash
House_Price_Prediction/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw housing data
â”‚   â””â”€â”€ processed/           # Cleaned and transformed data
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py       # Loads dataset
â”‚   â”œâ”€â”€ preprocess.py        # Data cleaning and feature scaling
â”‚   â”œâ”€â”€ train_model.py       # Model training logic
â”‚   â”œâ”€â”€ evaluate_model.py    # Model evaluation
â”‚   â””â”€â”€ predict.py           # Inference using saved model
â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ house_pipeline.py    # ZenML pipeline definition
â”œâ”€â”€ mlruns/                  # MLflow experiment logs
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md
````

---

## ğŸ” ZenML Pipeline Workflow

**ZenML Pipeline** ensures every step of your ML lifecycle is reproducible and trackable.

1. ğŸ§¾ **Data Loader Step** â†’ Loads and splits the dataset
2. ğŸ§¹ **Preprocessing Step** â†’ Cleans data and prepares features
3. âš™ï¸ **Trainer Step** â†’ Trains multiple models (Linear Regression, Random Forest, etc.)
4. ğŸ“ˆ **Evaluator Step** â†’ Logs metrics (MAE, RMSE, RÂ²) into MLflow
5. ğŸš€ **Deployment Step** â†’ Pushes the best model for serving

Run the pipeline:

```bash
zenml pipeline run house_price_pipeline
```

---

## ğŸ“Š Experiment Tracking with MLflow

Launch MLflow UI to visualize experiments:

```bash
mlflow ui
```

Then open: ğŸ‘‰ [http://127.0.0.1:5000](http://127.0.0.1:5000)

You can:

* Compare model performance
* Track hyperparameters and metrics
* Access saved model artifacts

ğŸ“¸ *Example Dashboard:*

```
Experiment: house_price_prediction
 â”œâ”€â”€ Run 1: Linear Regression â†’ RMSE: 2.85
 â”œâ”€â”€ Run 2: Random Forest â†’ RMSE: 1.78 âœ…
 â””â”€â”€ Run 3: XGBoost â†’ RMSE: 1.95
```

---

## ğŸŒ Model Serving

Once your model is logged, serve it locally:

```bash
mlflow models serve -m "runs:/<your_run_id>/model" --port 5001
```

Then send a prediction request:

```bash
curl -X POST -H "Content-Type: application/json" \
  --data '{"columns":["feature1","feature2","feature3"],"data":[[value1,value2,value3]]}' \
  http://127.0.0.1:5001/invocations
```

---

## âš™ï¸ Installation & Setup

```bash
# Clone the repository
git clone https://github.com/Anshul-Raj-S-V/House_prediction_system-Zenml-MLFLOW.git
cd House_prediction_system-Zenml-MLFLOW

# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate   # (on Windows)

# Install dependencies
pip install -r requirements.txt

# Initialize ZenML repository
zenml init

# Run pipeline
python test.py
```

---

## ğŸ’¡ Key Learnings

âœ¨ Reproducible ML workflows with **ZenML pipelines**
âœ¨ Model tracking, versioning, and registry using **MLflow**
âœ¨ End-to-end **MLOps implementation** from data to deployment
âœ¨ Hands-on with **model serving and API inference**

---

## ğŸ”® Future Enhancements

* ğŸ”§ Integrate **Docker** for containerized deployment
* ğŸš€ Deploy model via **AWS Sagemaker** or **Google Cloud Vertex AI**
* âš¡ Add **Hyperparameter Optimization** (Optuna integration)
* ğŸ§  Include **feature importance visualization** and **Streamlit dashboard**

```

---

Would you like me to **add a small ASCII architecture diagram** (like â€œData â†’ Train â†’ Evaluate â†’ Deployâ€) and badges like â€œBuilt with â¤ï¸ using ZenML & MLflowâ€?  
Itâ€™ll make your GitHub page *look like a professional open-source project*.
```
